unload bsc/commands (PATH, MANPATH) 
unload CUDA/9.1 (PATH, MANPATH, LD_LIBRARY_PATH, LIBRARY_PATH, C_INCLUDE_PATH,
CPLUS_INCLUDE_PATH, CUDA_HOME, CUDA_VERSION, CUDA_INC, CUDA_INSTALL_PATH) 
unload OPENMPI/3.0.0 (PATH, MANPATH, LD_LIBRARY_PATH, LIBRARY_PATH,
PKG_CONFIG_PATH, C_INCLUDE_PATH, CPLUS_INCLUDE_PATH, MPI, MPI_V) 
unload GCC/6.4.0 (PATH, MANPATH, INFOPATH, LD_LIBRARY_PATH, LIBRARY_PATH,
C_INCLUDE_PATH, CPLUS_INCLUDE_PATH, STD COMP VARS) 
load GCC/6.4.0 (PATH, MANPATH, INFOPATH, LD_LIBRARY_PATH, LIBRARY_PATH,
C_INCLUDE_PATH, CPLUS_INCLUDE_PATH, STD COMP VARS) 
load JAVA/ibm_8.0.5.15 (PATH, C_INCLUDE_PATH, CPLUS_INCLUDE_PATH, JAVA_HOME,
JAVA_ROOT, JAVA_BINDIR, SDK_HOME, JRE_HOME) 
load OPENMPI/3.0.0 (PATH, MANPATH, LD_LIBRARY_PATH, LIBRARY_PATH,
PKG_CONFIG_PATH, C_INCLUDE_PATH, CPLUS_INCLUDE_PATH, MPI, MPI_V) 
load CUDA/9.2 (PATH, MANPATH, LD_LIBRARY_PATH, LIBRARY_PATH, C_INCLUDE_PATH,
CPLUS_INCLUDE_PATH, CUDA_HOME, CUDA_VERSION, CUDA_INC, CUDA_INSTALL_PATH) 
load ATLAS/3.10.3 (LD_LIBRARY_PATH, LIBRARY_PATH, C_INCLUDE_PATH,
CPLUS_INCLUDE_PATH) 
INFO:tensorflow:Using config: {'_model_dir': '/gpfs/home/sam14/sam14015/task/proj/models/cifar10_resnet_v2_101.4', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  allow_growth: true
  visible_device_list: "0"
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x3fff62014710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Using temporary folder as model directory: /scratch/tmp/1112527/tmpmk2_i1o2
WARNING:tensorflow:Using temporary folder as model directory: /scratch/tmp/1112527/tmp4cwjurzg
WARNING:tensorflow:Using temporary folder as model directory: /scratch/tmp/1112527/tmpf7ruzo14
INFO:tensorflow:Using config: {'_model_dir': '/scratch/tmp/1112527/tmpmk2_i1o2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  allow_growth: true
  visible_device_list: "2"
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x3fff56fd46a0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:Using config: {'_model_dir': '/scratch/tmp/1112527/tmpf7ruzo14', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  allow_growth: true
  visible_device_list: "1"
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x3fff5c654748>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:Using config: {'_model_dir': '/scratch/tmp/1112527/tmp4cwjurzg', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  allow_growth: true
  visible_device_list: "3"
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x3fff603d4748>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
 ---------------------- Starting train for 2 ----------------------
INFO:tensorflow:Calling model_fn.
 Date is now: 2019-01-14 12:37:15.816283
 ---------------------- Starting train for 0 ----------------------
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
 ---------------------- Starting train for 1 ----------------------
INFO:tensorflow:Calling model_fn.
 ---------------------- Starting train for 3 ----------------------
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Scale of 0 disables regularizer.
INFO:tensorflow:Scale of 0 disables regularizer.
WARNING:tensorflow:From /gpfs/home/sam14/sam14015/task/proj/nets/resnet_v2.py:213: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:From /gpfs/home/sam14/sam14015/task/proj/nets/resnet_v2.py:213: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:From /gpfs/home/sam14/sam14015/task/proj/nets/resnet_v2.py:213: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
WARNING:tensorflow:From /gpfs/home/sam14/sam14015/task/proj/nets/resnet_v2.py:213: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
2019-01-14 12:37:57.595693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0035:03:00.0
totalMemory: 15.75GiB freeMemory: 15.34GiB
2019-01-14 12:37:57.595723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 2
2019-01-14 12:37:57.891035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-01-14 12:37:57.891075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      2 
2019-01-14 12:37:57.891085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   N 
2019-01-14 12:37:57.891630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14849 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0035:03:00.0, compute capability: 7.0)
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Graph was finalized.
2019-01-14 12:38:15.971887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0004:04:00.0
totalMemory: 15.75GiB freeMemory: 15.35GiB
2019-01-14 12:38:15.971951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2019-01-14 12:38:16.361334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-01-14 12:38:16.361387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2019-01-14 12:38:16.361402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2019-01-14 12:38:16.362094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14849 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0004:04:00.0, compute capability: 7.0)
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Graph was finalized.
2019-01-14 12:38:19.007278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0004:05:00.0
totalMemory: 15.75GiB freeMemory: 15.34GiB
2019-01-14 12:38:19.007327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 1
2019-01-14 12:38:19.037241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0035:04:00.0
totalMemory: 15.75GiB freeMemory: 15.34GiB
2019-01-14 12:38:19.037281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 3
2019-01-14 12:38:19.413876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-01-14 12:38:19.413929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      1 
2019-01-14 12:38:19.413943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   N 
2019-01-14 12:38:19.414783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14847 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0004:05:00.0, compute capability: 7.0)
2019-01-14 12:38:19.442464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-01-14 12:38:19.442515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      3 
2019-01-14 12:38:19.442530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 3:   N 
2019-01-14 12:38:19.443214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14847 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0035:04:00.0, compute capability: 7.0)
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
2019-01-14 12:38:37.504531: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:94] Filling up shuffle buffer (this may take a while): 9404 of 20000
2019-01-14 12:38:38.582633: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:94] Filling up shuffle buffer (this may take a while): 4805 of 20000
2019-01-14 12:38:38.582954: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:94] Filling up shuffle buffer (this may take a while): 5162 of 20000
2019-01-14 12:38:38.600549: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:94] Filling up shuffle buffer (this may take a while): 5248 of 20000
2019-01-14 12:38:47.503049: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:94] Filling up shuffle buffer (this may take a while): 18546 of 20000
2019-01-14 12:38:48.577219: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:94] Filling up shuffle buffer (this may take a while): 10393 of 20000
2019-01-14 12:38:48.578906: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:94] Filling up shuffle buffer (this may take a while): 10042 of 20000
2019-01-14 12:38:48.600364: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:94] Filling up shuffle buffer (this may take a while): 10873 of 20000
2019-01-14 12:38:49.148366: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:129] Shuffle buffer filled.
2019-01-14 12:38:58.577399: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:94] Filling up shuffle buffer (this may take a while): 16257 of 20000
2019-01-14 12:38:58.580025: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:94] Filling up shuffle buffer (this may take a while): 15948 of 20000
2019-01-14 12:38:58.601097: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:94] Filling up shuffle buffer (this may take a while): 17338 of 20000
2019-01-14 12:39:02.437615: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:129] Shuffle buffer filled.
2019-01-14 12:39:04.571518: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:129] Shuffle buffer filled.
2019-01-14 12:39:04.918964: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:129] Shuffle buffer filled.
INFO:tensorflow:loss = 2.5166621, step = 0
INFO:tensorflow:accuracy = 0.0625, loss = 2.5166621, global_step = 0
INFO:tensorflow:loss = 2.5746665, step = 0
INFO:tensorflow:loss = 2.4197555, step = 0
INFO:tensorflow:accuracy = 0.03125, loss = 2.5746665, global_step = 0
INFO:tensorflow:accuracy = 0.078125, loss = 2.4197555, global_step = 0
INFO:tensorflow:loss = 2.412438, step = 0
INFO:tensorflow:accuracy = 0.171875, loss = 2.412438, global_step = 0
WARNING: One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock. 
Stalled ops:
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_shortcut_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 1, 3]
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_conv3_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 0, 2]
WARNING: One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock. 
Stalled ops:
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_shortcut_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 1, 3]
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_conv3_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 0, 2]
WARNING: One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock. 
Stalled ops:
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_shortcut_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 1, 3]
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_conv3_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 0, 2]
WARNING: One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock. 
Stalled ops:
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_shortcut_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 1, 3]
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_conv3_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 0, 2]
WARNING: One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock. 
Stalled ops:
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_shortcut_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 1, 3]
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_conv3_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 0, 2]
WARNING: One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock. 
Stalled ops:
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_shortcut_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 1, 3]
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_conv3_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 0, 2]
WARNING: One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock. 
Stalled ops:
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_shortcut_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 1, 3]
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_conv3_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 0, 2]
WARNING: One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock. 
Stalled ops:
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_shortcut_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 1, 3]
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_conv3_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 0, 2]
WARNING: One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock. 
Stalled ops:
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_shortcut_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 1, 3]
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_conv3_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 0, 2]
WARNING: One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock. 
Stalled ops:
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_shortcut_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 1, 3]
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_conv3_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 0, 2]
WARNING: One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock. 
Stalled ops:
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_shortcut_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 1, 3]
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_conv3_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 0, 2]
WARNING: One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock. 
Stalled ops:
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_shortcut_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 1, 3]
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_conv3_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 0, 2]
WARNING: One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock. 
Stalled ops:
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_shortcut_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 1, 3]
train_op/DistributedGradientDescentOptimizer_Allreduce/HorovodAllreduce_train_op_gradients_resnet_v2_101_block3_unit_1_bottleneck_v2_conv3_BiasAdd_grad_tuple_control_dependency_1_0 [missing ranks: 0, 2]
slurmstepd: error: *** JOB 1112527 ON p9r3n05 CANCELLED AT 2019-01-14T12:52:16 DUE TO TIME LIMIT ***
